{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e53d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c17b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted working directory to project root\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('notebooks'):\n",
    "    os.chdir('..')\n",
    "    print(\"Adjusted working directory to project root\")\n",
    "\n",
    "from utils.preprocessing import PreprocessorFactory, DataQualityChecker\n",
    "import utils.model_training as mt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef449f",
   "metadata": {},
   "source": [
    "## Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0bba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/28 08:27:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/28 08:27:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session initialized successfully\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"ML_Pipeline_Training\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"Spark session initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee604514",
   "metadata": {},
   "source": [
    "## Build Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94682744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration built successfully:\n",
      "{'cv_folds': 3,\n",
      " 'feature_store_path': 'datamart/gold/feature_store/',\n",
      " 'hyperparameter_iterations': 10,\n",
      " 'label_store_path': 'datamart/gold/label_store/',\n",
      " 'model_artifacts_output': {},\n",
      " 'model_bank_directory': 'models/',\n",
      " 'model_train_date': datetime.datetime(2024, 9, 1, 0, 0),\n",
      " 'model_train_date_str': '2024-09-01',\n",
      " 'models_to_train': ['logistic_regression', 'random_forest', 'xgboost'],\n",
      " 'oot_end_date': datetime.datetime(2024, 8, 31, 0, 0),\n",
      " 'oot_period_months': 2,\n",
      " 'oot_start_date': datetime.datetime(2024, 7, 1, 0, 0),\n",
      " 'random_state': 88,\n",
      " 'train_test_end_date': datetime.datetime(2024, 6, 30, 0, 0),\n",
      " 'train_test_period_months': 12,\n",
      " 'train_test_ratio': 0.8,\n",
      " 'train_test_start_date': datetime.datetime(2023, 7, 1, 0, 0)}\n"
     ]
    }
   ],
   "source": [
    "config = mt.build_training_config(\n",
    "    training_date_str=\"2024-09-01\",\n",
    "    models_to_train=[\"logistic_regression\", \"random_forest\", \"xgboost\"],\n",
    "    train_test_period_months=12,\n",
    "    oot_period_months=2,\n",
    "    train_test_ratio=0.8,\n",
    "    cv_folds=3,\n",
    "    hyperparameter_iterations=10,\n",
    "    random_state=88,\n",
    "    feature_store_path=\"datamart/gold/feature_store/\",\n",
    "    label_store_path=\"datamart/gold/label_store/\",\n",
    "    model_bank_directory=\"models/\"\n",
    ")\n",
    "\n",
    "print(\"Training configuration built successfully:\")\n",
    "pprint.pprint(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69750af4",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98cf06f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from feature and label stores...\n",
      "Loading training data...\n",
      "Training period: 2023-07-01 to 2024-06-30\n",
      "OOT period: 2024-07-01 to 2024-08-31\n",
      "Loaded 6961 label records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 127189 feature records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (6961, 140)\n",
      "Training data loaded successfully: (6961, 140)\n",
      "\n",
      "Sample merged data:\n",
      "  Customer_ID snapshot_date  label  annual_income\n",
      "0  CUS_0x1015    2024-02-01      0   46951.019531\n",
      "1  CUS_0x10eb    2023-09-01      0   28315.949219\n",
      "2  CUS_0x10ff    2024-04-01      0   16341.075195\n",
      "3  CUS_0x112f    2024-04-01      1   75506.421875\n",
      "4  CUS_0x117d    2024-03-01      0   70779.179688\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training data from feature and label stores...\")\n",
    "data_pdf = mt.load_training_data(config, spark)\n",
    "\n",
    "if data_pdf is None:\n",
    "    raise ValueError(\"Failed to load training data\")\n",
    "\n",
    "print(f\"Training data loaded successfully: {data_pdf.shape}\")\n",
    "print(\"\\nSample merged data:\")\n",
    "print(data_pdf[['Customer_ID', 'snapshot_date', 'label', 'annual_income']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88358f8",
   "metadata": {},
   "source": [
    "## Validate Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f983c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating training data quality...\n",
      "Validating training data quality...\n",
      "Data quality validation completed\n",
      "Data quality validation passed\n",
      "Data Quality Report:\n",
      "{'data_quality_flags': [],\n",
      " 'data_shape': {'columns': 136, 'rows': 6961},\n",
      " 'feature_types': {'categorical': ['loan_id',\n",
      "                                   'credit_mix',\n",
      "                                   'payment_of_min_amount',\n",
      "                                   'occupation',\n",
      "                                   'age_group',\n",
      "                                   'occupation_category'],\n",
      "                   'numerical': ['annual_income',\n",
      "                                 'monthly_salary',\n",
      "                                 'credit_history_months',\n",
      "                                 'credit_utilization_ratio',\n",
      "                                 'delay_from_due_date',\n",
      "                                 'num_loans',\n",
      "                                 'num_delayed_payments',\n",
      "                                 'outstanding_debt',\n",
      "                                 'total_emi_monthly',\n",
      "                                 'amount_invested_monthly',\n",
      "                                 'monthly_balance',\n",
      "                                 'debt_to_income_ratio',\n",
      "                                 'emi_to_income_ratio',\n",
      "                                 'high_credit_utilization',\n",
      "                                 'high_debt_burden',\n",
      "                                 'payment_issues',\n",
      "                                 'financial_health_score',\n",
      "                                 'age',\n",
      "                                 'attributes_quality_score',\n",
      "                                 'fe_1_mean',\n",
      "                                 'fe_1_std',\n",
      "                                 'fe_1_min',\n",
      "                                 'fe_1_max',\n",
      "                                 'fe_2_mean',\n",
      "                                 'fe_2_std',\n",
      "                                 'fe_2_min',\n",
      "                                 'fe_2_max',\n",
      "                                 'fe_3_mean',\n",
      "                                 'fe_3_std',\n",
      "                                 'fe_3_min',\n",
      "                                 'fe_3_max',\n",
      "                                 'fe_4_mean',\n",
      "                                 'fe_4_std',\n",
      "                                 'fe_4_min',\n",
      "                                 'fe_4_max',\n",
      "                                 'fe_5_mean',\n",
      "                                 'fe_5_std',\n",
      "                                 'fe_5_min',\n",
      "                                 'fe_5_max',\n",
      "                                 'fe_6_mean',\n",
      "                                 'fe_6_std',\n",
      "                                 'fe_6_min',\n",
      "                                 'fe_6_max',\n",
      "                                 'fe_7_mean',\n",
      "                                 'fe_7_std',\n",
      "                                 'fe_7_min',\n",
      "                                 'fe_7_max',\n",
      "                                 'fe_8_mean',\n",
      "                                 'fe_8_std',\n",
      "                                 'fe_8_min',\n",
      "                                 'fe_8_max',\n",
      "                                 'fe_9_mean',\n",
      "                                 'fe_9_std',\n",
      "                                 'fe_9_min',\n",
      "                                 'fe_9_max',\n",
      "                                 'fe_10_mean',\n",
      "                                 'fe_10_std',\n",
      "                                 'fe_10_min',\n",
      "                                 'fe_10_max',\n",
      "                                 'fe_11_mean',\n",
      "                                 'fe_11_std',\n",
      "                                 'fe_11_min',\n",
      "                                 'fe_11_max',\n",
      "                                 'fe_12_mean',\n",
      "                                 'fe_12_std',\n",
      "                                 'fe_12_min',\n",
      "                                 'fe_12_max',\n",
      "                                 'fe_13_mean',\n",
      "                                 'fe_13_std',\n",
      "                                 'fe_13_min',\n",
      "                                 'fe_13_max',\n",
      "                                 'fe_14_mean',\n",
      "                                 'fe_14_std',\n",
      "                                 'fe_14_min',\n",
      "                                 'fe_14_max',\n",
      "                                 'fe_15_mean',\n",
      "                                 'fe_15_std',\n",
      "                                 'fe_15_min',\n",
      "                                 'fe_15_max',\n",
      "                                 'fe_16_mean',\n",
      "                                 'fe_16_std',\n",
      "                                 'fe_16_min',\n",
      "                                 'fe_16_max',\n",
      "                                 'fe_17_mean',\n",
      "                                 'fe_17_std',\n",
      "                                 'fe_17_min',\n",
      "                                 'fe_17_max',\n",
      "                                 'fe_18_mean',\n",
      "                                 'fe_18_std',\n",
      "                                 'fe_18_min',\n",
      "                                 'fe_18_max',\n",
      "                                 'fe_19_mean',\n",
      "                                 'fe_19_std',\n",
      "                                 'fe_19_min',\n",
      "                                 'fe_19_max',\n",
      "                                 'fe_20_mean',\n",
      "                                 'fe_20_std',\n",
      "                                 'fe_20_min',\n",
      "                                 'fe_20_max',\n",
      "                                 'clickstream_record_count',\n",
      "                                 'clickstream_time_span_days',\n",
      "                                 'fe_1_cv',\n",
      "                                 'fe_2_cv',\n",
      "                                 'fe_3_cv',\n",
      "                                 'fe_4_cv',\n",
      "                                 'fe_5_cv',\n",
      "                                 'fe_6_cv',\n",
      "                                 'fe_7_cv',\n",
      "                                 'fe_8_cv',\n",
      "                                 'fe_9_cv',\n",
      "                                 'fe_10_cv',\n",
      "                                 'fe_11_cv',\n",
      "                                 'fe_12_cv',\n",
      "                                 'fe_13_cv',\n",
      "                                 'fe_14_cv',\n",
      "                                 'fe_15_cv',\n",
      "                                 'fe_16_cv',\n",
      "                                 'fe_17_cv',\n",
      "                                 'fe_18_cv',\n",
      "                                 'fe_19_cv',\n",
      "                                 'fe_20_cv',\n",
      "                                 'age_income_interaction',\n",
      "                                 'relative_credit_history',\n",
      "                                 'age_adjusted_debt_ratio',\n",
      "                                 'has_clickstream_data',\n",
      "                                 'has_attributes_data',\n",
      "                                 'has_financial_data',\n",
      "                                 'data_completeness_score']},\n",
      " 'label_distribution': {'class_counts': {0: 4984, 1: 1977},\n",
      "                        'class_proportions': {0: 0.7159890820284441,\n",
      "                                              1: 0.2840109179715558},\n",
      "                        'is_balanced': np.True_},\n",
      " 'missing_values': {'columns_with_missing': ['amount_invested_monthly',\n",
      "                                             'relative_credit_history'],\n",
      "                    'high_missing_columns': [],\n",
      "                    'missing_percentage': np.float64(0.03834388230223852),\n",
      "                    'total_missing': np.int64(363)},\n",
      " 'timestamp': '2025-06-28 08:28:23'}\n",
      "\n",
      "Data quality validation passed successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Validating training data quality...\")\n",
    "quality_report = mt.validate_training_data(data_pdf, config)\n",
    "\n",
    "print(\"Data Quality Report:\")\n",
    "pprint.pprint(quality_report)\n",
    "\n",
    "if quality_report.get('data_quality_flags'):\n",
    "    print(f\"\\nWARNING: Data quality issues detected: {quality_report['data_quality_flags']}\")\n",
    "else:\n",
    "    print(\"\\nData quality validation passed successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a91a01",
   "metadata": {},
   "source": [
    "## Prepare Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1936c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training datasets...\n",
      "Preparing training datasets...\n",
      "Dataset preparation completed:\n",
      "  Train: 4766 samples, label rate: 0.281\n",
      "  Test: 1192 samples, label rate: 0.293\n",
      "  OOT: 1003 samples, label rate: 0.290\n",
      "  Features: 136\n",
      "Training datasets prepared successfully:\n",
      "  Train: 4766 samples, label rate: 0.281\n",
      "  Test: 1192 samples, label rate: 0.293\n",
      "  OOT: 1003 samples, label rate: 0.290\n",
      "  Features: 136\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing training datasets...\")\n",
    "datasets = mt.prepare_training_datasets(data_pdf, config)\n",
    "\n",
    "if datasets is None:\n",
    "    raise ValueError(\"Failed to prepare training datasets\")\n",
    "\n",
    "print(\"Training datasets prepared successfully:\")\n",
    "print(f\"  Train: {datasets['X_train'].shape[0]} samples, label rate: {datasets['y_train'].mean():.3f}\")\n",
    "print(f\"  Test: {datasets['X_test'].shape[0]} samples, label rate: {datasets['y_test'].mean():.3f}\")\n",
    "print(f\"  OOT: {datasets['X_oot'].shape[0]} samples, label rate: {datasets['y_oot'].mean():.3f}\")\n",
    "print(f\"  Features: {len(datasets['feature_columns'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4bd55a",
   "metadata": {},
   "source": [
    "## Model-Specific Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211a67a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model-specific preprocessing...\n",
      "\n",
      "Processing logistic_regression...\n",
      "Preparing preprocessing for logistic_regression...\n",
      "[LR Preprocessor] Starting preprocessing for 4766 samples with 136 features\n",
      "[LR Preprocessor] Selected 7 financial features\n",
      "[LR Preprocessor] Selected 2 demographic features\n",
      "[LR Preprocessor] Selected 4 categorical features\n",
      "[LR Preprocessor] Selected 10 clickstream features\n",
      "[LR Preprocessor] Selected 3 quality features\n",
      "[LR Preprocessor] Preprocessing complete: 136 -> 36 features\n",
      "logistic_regression: 136 -> 36 features\n",
      "✓ logistic_regression: 136 -> 36 features\n",
      "\n",
      "Processing random_forest...\n",
      "Preparing preprocessing for random_forest...\n",
      "[RF Preprocessor] Starting preprocessing for 4766 samples with 136 features\n",
      "[RF Preprocessor] Selected 20 financial features\n",
      "[RF Preprocessor] Selected 100 clickstream features\n",
      "[RF Preprocessor] Selected 6 interaction features\n",
      "[RF Preprocessor] Selected 9 demographic features\n",
      "[RF Preprocessor] Selected 5 quality features\n",
      "[RF Preprocessor] Preprocessing complete: 136 -> 140 features\n",
      "random_forest: 136 -> 140 features\n",
      "✓ random_forest: 136 -> 140 features\n",
      "\n",
      "Processing xgboost...\n",
      "Preparing preprocessing for xgboost...\n",
      "[XGB Preprocessor] Starting preprocessing for 4766 samples with 136 features\n",
      "[XGB Preprocessor] Selected 135 features for training\n",
      "[XGB Preprocessor] Preprocessing complete: 136 -> 135 features\n",
      "xgboost: 136 -> 135 features\n",
      "✓ xgboost: 136 -> 135 features\n",
      "\n",
      "Models ready for training: ['logistic_regression', 'random_forest', 'xgboost']\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing model-specific preprocessing...\")\n",
    "preprocessing_results = {}\n",
    "\n",
    "for model_type in config[\"models_to_train\"]:\n",
    "    print(f\"\\nProcessing {model_type}...\")\n",
    "    \n",
    "    preprocessing_result = mt.prepare_model_preprocessing(\n",
    "        datasets, model_type, config[\"random_state\"]\n",
    "    )\n",
    "    \n",
    "    if preprocessing_result is None:\n",
    "        print(f\"✗ {model_type} preprocessing failed\")\n",
    "        continue\n",
    "    \n",
    "    preprocessing_results[model_type] = preprocessing_result\n",
    "    stats = preprocessing_result['preprocessing_stats']\n",
    "    print(f\"✓ {model_type}: {stats['original_features']} -> {stats['final_features']} features\")\n",
    "\n",
    "successful_models = list(preprocessing_results.keys())\n",
    "config[\"models_to_train\"] = successful_models\n",
    "print(f\"\\nModels ready for training: {successful_models}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8235f",
   "metadata": {},
   "source": [
    "## Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b28fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training phase...\n",
      "\n",
      "============================================================\n",
      "TRAINING LOGISTIC_REGRESSION\n",
      "============================================================\n",
      "\n",
      "[LOGISTIC_REGRESSION] Starting model training...\n",
      "[LOGISTIC_REGRESSION] Train samples: 4766\n",
      "[LOGISTIC_REGRESSION] Test samples: 1192\n",
      "[LOGISTIC_REGRESSION] OOT samples: 1003\n",
      "[LOGISTIC_REGRESSION] Features: 36\n",
      "[LOGISTIC_REGRESSION] Starting hyperparameter search...\n",
      "[LOGISTIC_REGRESSION] Search iterations: 10\n",
      "[LOGISTIC_REGRESSION] CV folds: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/airflow/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOGISTIC_REGRESSION] Best CV score: 0.8041\n",
      "[LOGISTIC_REGRESSION] Performance Results:\n",
      "[LOGISTIC_REGRESSION]   Train AUC: 0.8114 (Gini: 0.623)\n",
      "[LOGISTIC_REGRESSION]   Test AUC:  0.8060 (Gini: 0.612)\n",
      "[LOGISTIC_REGRESSION]   OOT AUC:   0.7878 (Gini: 0.576)\n",
      "[LOGISTIC_REGRESSION] Training completed in 6.06 seconds\n",
      "✓ logistic_regression training completed successfully\n",
      "\n",
      "============================================================\n",
      "TRAINING RANDOM_FOREST\n",
      "============================================================\n",
      "\n",
      "[RANDOM_FOREST] Starting model training...\n",
      "[RANDOM_FOREST] Train samples: 4766\n",
      "[RANDOM_FOREST] Test samples: 1192\n",
      "[RANDOM_FOREST] OOT samples: 1003\n",
      "[RANDOM_FOREST] Features: 140\n",
      "[RANDOM_FOREST] Starting hyperparameter search...\n",
      "[RANDOM_FOREST] Search iterations: 10\n",
      "[RANDOM_FOREST] CV folds: 3\n",
      "[RANDOM_FOREST] Best CV score: 0.8668\n",
      "[RANDOM_FOREST] Performance Results:\n",
      "[RANDOM_FOREST]   Train AUC: 0.9868 (Gini: 0.974)\n",
      "[RANDOM_FOREST]   Test AUC:  0.8802 (Gini: 0.760)\n",
      "[RANDOM_FOREST]   OOT AUC:   0.8519 (Gini: 0.704)\n",
      "[RANDOM_FOREST] Training completed in 26.09 seconds\n",
      "✓ random_forest training completed successfully\n",
      "\n",
      "============================================================\n",
      "TRAINING XGBOOST\n",
      "============================================================\n",
      "\n",
      "[XGBOOST] Starting model training...\n",
      "[XGBOOST] Train samples: 4766\n",
      "[XGBOOST] Test samples: 1192\n",
      "[XGBOOST] OOT samples: 1003\n",
      "[XGBOOST] Features: 135\n",
      "[XGBOOST] Starting hyperparameter search...\n",
      "[XGBOOST] Search iterations: 10\n",
      "[XGBOOST] CV folds: 3\n",
      "[XGBOOST] Best CV score: 0.8884\n",
      "[XGBOOST] Performance Results:\n",
      "[XGBOOST]   Train AUC: 0.9686 (Gini: 0.937)\n",
      "[XGBOOST]   Test AUC:  0.8927 (Gini: 0.785)\n",
      "[XGBOOST]   OOT AUC:   0.8845 (Gini: 0.769)\n",
      "[XGBOOST] Training completed in 9.58 seconds\n",
      "✓ xgboost training completed successfully\n",
      "\n",
      "Training phase completed: 3/3 models trained successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting model training phase...\")\n",
    "model_artifacts = {}\n",
    "training_results = {}\n",
    "\n",
    "for model_type in config[\"models_to_train\"]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING {model_type.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    preprocessing_result = preprocessing_results[model_type]\n",
    "    \n",
    "    model_artifact = mt.train_single_model(\n",
    "        model_type=model_type,\n",
    "        preprocessing_result=preprocessing_result,\n",
    "        datasets=datasets,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    if model_artifact is None:\n",
    "        print(f\"✗ {model_type} training failed\")\n",
    "        training_results[model_type] = {'error': 'Training failed'}\n",
    "        continue\n",
    "    \n",
    "    model_artifacts[model_type] = model_artifact\n",
    "    training_results[model_type] = {\n",
    "        'auc_train': model_artifact['results']['auc_train'],\n",
    "        'auc_test': model_artifact['results']['auc_test'],\n",
    "        'auc_oot': model_artifact['results']['auc_oot'],\n",
    "        'gini_train': model_artifact['results']['gini_train'],\n",
    "        'gini_test': model_artifact['results']['gini_test'],\n",
    "        'gini_oot': model_artifact['results']['gini_oot'],\n",
    "        'training_time': model_artifact['training_metadata']['training_time_seconds'],\n",
    "        'cv_score': model_artifact['results']['cv_score']\n",
    "    }\n",
    "    \n",
    "    print(f\"✓ {model_type} training completed successfully\")\n",
    "\n",
    "print(f\"\\nTraining phase completed: {len(model_artifacts)}/{len(config['models_to_train'])} models trained successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c46bac",
   "metadata": {},
   "source": [
    "## Training Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c6d048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING RESULTS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Model Performance Comparison:\n",
      "                     auc_train  auc_test   auc_oot  gini_train  gini_test  \\\n",
      "logistic_regression   0.811373  0.806048  0.787810    0.622747   0.612096   \n",
      "random_forest         0.986768  0.880244  0.851949    0.973536   0.760488   \n",
      "xgboost               0.968645  0.892742  0.884527    0.937290   0.785484   \n",
      "\n",
      "                     gini_oot  training_time  cv_score  \n",
      "logistic_regression  0.575621       6.058401  0.804054  \n",
      "random_forest        0.703898      26.094765  0.866796  \n",
      "xgboost              0.769055       9.578844  0.888354  \n",
      "\n",
      "Best model selected: xgboost\n",
      "Selection metric (auc_test): 0.8927\n",
      "\n",
      "Best model selected: xgboost\n",
      "Test AUC: 0.8927\n",
      "Test Gini: 0.785\n",
      "OOT AUC (final validation): 0.8845\n",
      "OOT Gini (final validation): 0.769\n",
      "\n",
      "Model Ranking (by Test AUC):\n",
      "1. xgboost: Test AUC 0.8927, OOT AUC 0.8845\n",
      "2. random_forest: Test AUC 0.8802, OOT AUC 0.8519\n",
      "3. logistic_regression: Test AUC 0.8060, OOT AUC 0.7878\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING RESULTS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_df = pd.DataFrame(training_results).T\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "best_model_info = mt.select_best_model(model_artifacts, selection_metric='auc_test')\n",
    "\n",
    "if best_model_info:\n",
    "    best_model_type, best_model_artifact = best_model_info\n",
    "    print(f\"\\nBest model selected: {best_model_type}\")\n",
    "    print(f\"Test AUC: {best_model_artifact['results']['auc_test']:.4f}\")\n",
    "    print(f\"Test Gini: {best_model_artifact['results']['gini_test']:.3f}\")\n",
    "    print(f\"OOT AUC (final validation): {best_model_artifact['results']['auc_oot']:.4f}\")\n",
    "    print(f\"OOT Gini (final validation): {best_model_artifact['results']['gini_oot']:.3f}\")\n",
    "else:\n",
    "    print(\"\\nNo valid models found for selection\")\n",
    "\n",
    "if len(model_artifacts) > 1:\n",
    "    print(f\"\\nModel Ranking (by Test AUC):\")\n",
    "    valid_results = results_df[results_df['auc_test'].notna()].sort_values('auc_test', ascending=False)\n",
    "    for i, (model, row) in enumerate(valid_results.iterrows(), 1):\n",
    "        print(f\"{i}. {model}: Test AUC {row['auc_test']:.4f}, OOT AUC {row['auc_oot']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4b5cd",
   "metadata": {},
   "source": [
    "## Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025f1995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model artifacts to model bank...\n",
      "✓ logistic_regression saved to: models/credit_model_logistic_regression_2024_09_01.pkl\n",
      "✓ logistic_regression preprocessor saved to: models/credit_model_logistic_regression_2024_09_01_preprocessor.pkl\n",
      "✓ random_forest saved to: models/credit_model_random_forest_2024_09_01.pkl\n",
      "✓ random_forest preprocessor saved to: models/credit_model_random_forest_2024_09_01_preprocessor.pkl\n",
      "✓ xgboost saved to: models/credit_model_xgboost_2024_09_01.pkl\n",
      "✓ xgboost preprocessor saved to: models/credit_model_xgboost_2024_09_01_preprocessor.pkl\n",
      "Model artifacts saved successfully:\n",
      "  logistic_regression: models/credit_model_logistic_regression_2024_09_01.pkl\n",
      "  random_forest: models/credit_model_random_forest_2024_09_01.pkl\n",
      "  xgboost: models/credit_model_xgboost_2024_09_01.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving model artifacts to model bank...\")\n",
    "saved_paths = mt.save_model_artifacts(model_artifacts, config)\n",
    "\n",
    "print(f\"Model artifacts saved successfully:\")\n",
    "for model_type, path in saved_paths.items():\n",
    "    print(f\"  {model_type}: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89ccc31",
   "metadata": {},
   "source": [
    "## Validate Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ac7209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating saved model artifacts...\n",
      "\n",
      "[VALIDATION] Testing logistic_regression inference...\n",
      "[VALIDATION] ✓ logistic_regression validation successful - AUC: 0.8060\n",
      "\n",
      "[VALIDATION] Testing random_forest inference...\n",
      "[VALIDATION] ✓ random_forest validation successful - AUC: 0.8802\n",
      "\n",
      "[VALIDATION] Testing xgboost inference...\n",
      "[VALIDATION] ✓ xgboost validation successful - AUC: 0.8927\n",
      "Model validation results:\n",
      "✓ logistic_regression: Validation successful - AUC: 0.8060\n",
      "✓ random_forest: Validation successful - AUC: 0.8802\n",
      "✓ xgboost: Validation successful - AUC: 0.8927\n"
     ]
    }
   ],
   "source": [
    "print(\"Validating saved model artifacts...\")\n",
    "validation_results = mt.validate_model_artifacts(model_artifacts, datasets)\n",
    "\n",
    "print(\"Model validation results:\")\n",
    "for model_type, result in validation_results.items():\n",
    "    if result.get('validation_successful'):\n",
    "        print(f\"✓ {model_type}: Validation successful - AUC: {result['auc_score']:.4f}\")\n",
    "    else:\n",
    "        print(f\"✗ {model_type}: Validation failed - {result.get('error', 'Unknown error')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf266a88",
   "metadata": {},
   "source": [
    "## Training Session Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c54be007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING SESSION COMPLETE\n",
      "================================================================================\n",
      "Training Configuration:\n",
      "  Training Date: 2024-09-01\n",
      "  Training Period: 2023-07-01 to 2024-06-30\n",
      "  OOT Period: 2024-07-01 to 2024-08-31\n",
      "  Models Requested: logistic_regression, random_forest, xgboost\n",
      "\n",
      "Training Outcomes:\n",
      "  Models Trained Successfully: 3/3\n",
      "  Successful: logistic_regression, random_forest, xgboost\n",
      "\n",
      "Best Model Summary:\n",
      "  Model Type: xgboost\n",
      "  Model Version: credit_model_xgboost_2024_09_01\n",
      "  Test AUC: 0.8927\n",
      "  OOT AUC: 0.8845\n",
      "  Training Time: 9.6s\n",
      "  Feature Count: 135\n",
      "\n",
      "Data Summary:\n",
      "  Total Records: 6,961\n",
      "  Train Samples: 4,766 (0.281 default rate)\n",
      "  Test Samples: 1,192 (0.293 default rate)\n",
      "  OOT Samples: 1,003 (0.290 default rate)\n",
      "\n",
      "Model Bank:\n",
      "  Location: /opt/airflow/models\n",
      "  Artifacts Saved: 3\n",
      "  Validation Success Rate: 3/3\n",
      "\n",
      "Spark session terminated successfully\n",
      "\n",
      "================================================================================\n",
      "TRAINING PIPELINE EXECUTION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING SESSION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  Training Date: {config['model_train_date_str']}\")\n",
    "print(f\"  Training Period: {config['train_test_start_date'].date()} to {config['train_test_end_date'].date()}\")\n",
    "print(f\"  OOT Period: {config['oot_start_date'].date()} to {config['oot_end_date'].date()}\")\n",
    "print(f\"  Models Requested: {', '.join(config['models_to_train'])}\")\n",
    "\n",
    "successful_models = list(model_artifacts.keys())\n",
    "failed_models = [m for m in config['models_to_train'] if m not in model_artifacts]\n",
    "\n",
    "print(f\"\\nTraining Outcomes:\")\n",
    "print(f\"  Models Trained Successfully: {len(successful_models)}/{len(config['models_to_train'])}\")\n",
    "if successful_models:\n",
    "    print(f\"  Successful: {', '.join(successful_models)}\")\n",
    "if failed_models:\n",
    "    print(f\"  Failed: {', '.join(failed_models)}\")\n",
    "\n",
    "if best_model_info:\n",
    "    best_model_type, best_model_artifact = best_model_info\n",
    "    print(f\"\\nBest Model Summary:\")\n",
    "    print(f\"  Model Type: {best_model_type}\")\n",
    "    print(f\"  Model Version: {best_model_artifact['model_version']}\")\n",
    "    print(f\"  Test AUC: {best_model_artifact['results']['auc_test']:.4f}\")\n",
    "    print(f\"  OOT AUC: {best_model_artifact['results']['auc_oot']:.4f}\")\n",
    "    print(f\"  Training Time: {best_model_artifact['training_metadata']['training_time_seconds']:.1f}s\")\n",
    "    print(f\"  Feature Count: {best_model_artifact['data_stats']['feature_count']}\")\n",
    "\n",
    "print(f\"\\nData Summary:\")\n",
    "print(f\"  Total Records: {len(data_pdf):,}\")\n",
    "print(f\"  Train Samples: {datasets['X_train'].shape[0]:,} ({datasets['y_train'].mean():.3f} default rate)\")\n",
    "print(f\"  Test Samples: {datasets['X_test'].shape[0]:,} ({datasets['y_test'].mean():.3f} default rate)\")\n",
    "print(f\"  OOT Samples: {datasets['X_oot'].shape[0]:,} ({datasets['y_oot'].mean():.3f} default rate)\")\n",
    "\n",
    "print(f\"\\nModel Bank:\")\n",
    "print(f\"  Location: {os.path.abspath(config['model_bank_directory'])}\")\n",
    "print(f\"  Artifacts Saved: {len(saved_paths)}\")\n",
    "\n",
    "successful_validations = len([r for r in validation_results.values() if r.get('validation_successful')])\n",
    "print(f\"  Validation Success Rate: {successful_validations}/{len(validation_results)}\")\n",
    "\n",
    "if 'spark' in locals():\n",
    "    spark.stop()\n",
    "    print(\"\\nSpark session terminated successfully\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING PIPELINE EXECUTION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
