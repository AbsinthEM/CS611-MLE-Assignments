{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Pipeline - Medallion Architecture\n",
    "\n",
    "This notebook implements a comprehensive feature engineering pipeline following the Medallion Architecture:\n",
    "- **Bronze Layer**: Raw data ingestion with metadata\n",
    "- **Silver Layer**: Data cleaning and standardization\n",
    "- **Gold Layer**: ML-ready feature store creation\n",
    "\n",
    "The pipeline processes three data sources:\n",
    "1. Clickstream features (behavioral data)\n",
    "2. Customer attributes (demographic data)\n",
    "3. Financial features (financial health data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "\n",
    "# Import our feature processing modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils.feature_processing_bronze_table\n",
    "import utils.feature_processing_silver_table\n",
    "import utils.feature_processing_gold_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted working directory to project root\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure we're working from project root\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('notebooks'):\n",
    "    os.chdir('..')\n",
    "    print(\"Adjusted working directory to project root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PySpark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/22 08:02:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"feature_engineering\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"Spark session initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering date range: 2023-01-01 to 2024-12-01\n",
      "Lookback period: 6 months\n"
     ]
    }
   ],
   "source": [
    "# Set up configuration - using same date range as label engineering for consistency\n",
    "start_date_str = \"2023-01-01\"\n",
    "end_date_str = \"2024-12-01\"\n",
    "\n",
    "# Feature engineering specific parameters\n",
    "lookback_months = 6  # How many months of history to use for time-aware features\n",
    "\n",
    "print(f\"Feature engineering date range: {start_date_str} to {end_date_str}\")\n",
    "print(f\"Lookback period: {lookback_months} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 24 monthly snapshots\n",
      "Sample dates: ['2023-01-01', '2023-02-01', '2023-03-01', '2023-04-01', '2023-05-01']...['2024-11-01', '2024-12-01']\n"
     ]
    }
   ],
   "source": [
    "# Generate list of dates to process\n",
    "def generate_first_of_month_dates(start_date_str, end_date_str):\n",
    "    \"\"\"Generate first-of-month dates for processing\"\"\"\n",
    "    # Convert the date strings to datetime objects\n",
    "    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # List to store the first of month dates\n",
    "    first_of_month_dates = []\n",
    "\n",
    "    # Start from the first of the month of the start_date\n",
    "    current_date = datetime(start_date.year, start_date.month, 1)\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        # Append the date in yyyy-mm-dd format\n",
    "        first_of_month_dates.append(current_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        # Move to the first of the next month\n",
    "        if current_date.month == 12:\n",
    "            current_date = datetime(current_date.year + 1, 1, 1)\n",
    "        else:\n",
    "            current_date = datetime(current_date.year, current_date.month + 1, 1)\n",
    "\n",
    "    return first_of_month_dates\n",
    "\n",
    "dates_str_lst = generate_first_of_month_dates(start_date_str, end_date_str)\n",
    "print(f\"Processing {len(dates_str_lst)} monthly snapshots\")\n",
    "print(f\"Sample dates: {dates_str_lst[:5]}...{dates_str_lst[-2:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronze Layer - Raw Data Ingestion\n",
    "\n",
    "The Bronze layer preserves raw data in its original format while adding metadata for lineage tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bronze layer directories\n",
    "bronze_clickstream_directory = \"datamart/bronze/clickstream/\"\n",
    "bronze_attributes_directory = \"datamart/bronze/attributes/\"\n",
    "bronze_financials_directory = \"datamart/bronze/financials/\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [bronze_clickstream_directory, bronze_attributes_directory, bronze_financials_directory]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Bronze Layer - Clickstream ===\n",
      "Processing clickstream bronze for 2023-01-01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clickstream 2023-01-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_01_01.csv\n",
      "Clickstream 2023-02-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_02_01.csv\n",
      "Clickstream 2023-03-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_03_01.csv\n",
      "Clickstream 2023-04-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_04_01.csv\n",
      "Clickstream 2023-05-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_05_01.csv\n",
      "Clickstream 2023-06-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_06_01.csv\n",
      "Processing clickstream bronze for 2023-07-01...\n",
      "Clickstream 2023-07-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_07_01.csv\n",
      "Clickstream 2023-08-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_08_01.csv\n",
      "Clickstream 2023-09-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_09_01.csv\n",
      "Clickstream 2023-10-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_10_01.csv\n",
      "Clickstream 2023-11-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_11_01.csv\n",
      "Clickstream 2023-12-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2023_12_01.csv\n",
      "Processing clickstream bronze for 2024-01-01...\n",
      "Clickstream 2024-01-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_01_01.csv\n",
      "Clickstream 2024-02-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_02_01.csv\n",
      "Clickstream 2024-03-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_03_01.csv\n",
      "Clickstream 2024-04-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_04_01.csv\n",
      "Clickstream 2024-05-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_05_01.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clickstream 2024-06-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_06_01.csv\n",
      "Processing clickstream bronze for 2024-07-01...\n",
      "Clickstream 2024-07-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_07_01.csv\n",
      "Clickstream 2024-08-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_08_01.csv\n",
      "Clickstream 2024-09-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_09_01.csv\n",
      "Clickstream 2024-10-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_10_01.csv\n",
      "Clickstream 2024-11-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_11_01.csv\n",
      "Clickstream 2024-12-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_12_01.csv\n",
      "Clickstream bronze processing completed for 24 snapshots\n"
     ]
    }
   ],
   "source": [
    "# Process Bronze Layer - Clickstream Features\n",
    "print(\"=== Processing Bronze Layer - Clickstream ===\")\n",
    "for i, date_str in enumerate(dates_str_lst):\n",
    "    if i % 6 == 0:  # Print progress every 6 months\n",
    "        print(f\"Processing clickstream bronze for {date_str}...\")\n",
    "    \n",
    "    utils.feature_processing_bronze_table.process_clickstream_bronze_table(\n",
    "        date_str, bronze_clickstream_directory, spark)\n",
    "\n",
    "print(f\"Clickstream bronze processing completed for {len(dates_str_lst)} snapshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Bronze Layer - Attributes ===\n",
      "Processing attributes bronze for 2023-01-01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes 2023-01-01 row count: 530\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_01_01.csv\n",
      "Attributes 2023-02-01 row count: 501\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_02_01.csv\n",
      "Attributes 2023-03-01 row count: 506\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_03_01.csv\n",
      "Attributes 2023-04-01 row count: 510\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_04_01.csv\n",
      "Attributes 2023-05-01 row count: 521\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_05_01.csv\n",
      "Attributes 2023-06-01 row count: 517\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_06_01.csv\n",
      "Processing attributes bronze for 2023-07-01...\n",
      "Attributes 2023-07-01 row count: 471\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_07_01.csv\n",
      "Attributes 2023-08-01 row count: 481\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_08_01.csv\n",
      "Attributes 2023-09-01 row count: 454\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_09_01.csv\n",
      "Attributes 2023-10-01 row count: 487\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_10_01.csv\n",
      "Attributes 2023-11-01 row count: 491\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_11_01.csv\n",
      "Attributes 2023-12-01 row count: 489\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2023_12_01.csv\n",
      "Processing attributes bronze for 2024-01-01...\n",
      "Attributes 2024-01-01 row count: 485\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_01_01.csv\n",
      "Attributes 2024-02-01 row count: 518\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_02_01.csv\n",
      "Attributes 2024-03-01 row count: 511\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_03_01.csv\n",
      "Attributes 2024-04-01 row count: 513\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_04_01.csv\n",
      "Attributes 2024-05-01 row count: 491\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_05_01.csv\n",
      "Attributes 2024-06-01 row count: 498\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_06_01.csv\n",
      "Processing attributes bronze for 2024-07-01...\n",
      "Attributes 2024-07-01 row count: 505\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_07_01.csv\n",
      "Attributes 2024-08-01 row count: 543\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_08_01.csv\n",
      "Attributes 2024-09-01 row count: 493\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_09_01.csv\n",
      "Attributes 2024-10-01 row count: 456\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_10_01.csv\n",
      "Attributes 2024-11-01 row count: 488\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_11_01.csv\n",
      "Attributes 2024-12-01 row count: 515\n",
      "Attributes bronze saved to: datamart/bronze/attributes/bronze_attributes_2024_12_01.csv\n",
      "Attributes bronze processing completed for 24 snapshots\n"
     ]
    }
   ],
   "source": [
    "# Process Bronze Layer - Customer Attributes\n",
    "print(\"=== Processing Bronze Layer - Attributes ===\")\n",
    "for i, date_str in enumerate(dates_str_lst):\n",
    "    if i % 6 == 0:  # Print progress every 6 months\n",
    "        print(f\"Processing attributes bronze for {date_str}...\")\n",
    "    \n",
    "    utils.feature_processing_bronze_table.process_attributes_bronze_table(\n",
    "        date_str, bronze_attributes_directory, spark)\n",
    "\n",
    "print(f\"Attributes bronze processing completed for {len(dates_str_lst)} snapshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Bronze Layer - Financials ===\n",
      "Processing financials bronze for 2023-01-01...\n",
      "Financials 2023-01-01 row count: 530\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_01_01.csv\n",
      "Financials 2023-02-01 row count: 501\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_02_01.csv\n",
      "Financials 2023-03-01 row count: 506\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_03_01.csv\n",
      "Financials 2023-04-01 row count: 510\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_04_01.csv\n",
      "Financials 2023-05-01 row count: 521\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_05_01.csv\n",
      "Financials 2023-06-01 row count: 517\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_06_01.csv\n",
      "Processing financials bronze for 2023-07-01...\n",
      "Financials 2023-07-01 row count: 471\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_07_01.csv\n",
      "Financials 2023-08-01 row count: 481\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_08_01.csv\n",
      "Financials 2023-09-01 row count: 454\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_09_01.csv\n",
      "Financials 2023-10-01 row count: 487\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_10_01.csv\n",
      "Financials 2023-11-01 row count: 491\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_11_01.csv\n",
      "Financials 2023-12-01 row count: 489\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2023_12_01.csv\n",
      "Processing financials bronze for 2024-01-01...\n",
      "Financials 2024-01-01 row count: 485\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_01_01.csv\n",
      "Financials 2024-02-01 row count: 518\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_02_01.csv\n",
      "Financials 2024-03-01 row count: 511\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_03_01.csv\n",
      "Financials 2024-04-01 row count: 513\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_04_01.csv\n",
      "Financials 2024-05-01 row count: 491\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_05_01.csv\n",
      "Financials 2024-06-01 row count: 498\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_06_01.csv\n",
      "Processing financials bronze for 2024-07-01...\n",
      "Financials 2024-07-01 row count: 505\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_07_01.csv\n",
      "Financials 2024-08-01 row count: 543\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_08_01.csv\n",
      "Financials 2024-09-01 row count: 493\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_09_01.csv\n",
      "Financials 2024-10-01 row count: 456\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_10_01.csv\n",
      "Financials 2024-11-01 row count: 488\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_11_01.csv\n",
      "Financials 2024-12-01 row count: 515\n",
      "Financials bronze saved to: datamart/bronze/financials/bronze_financials_2024_12_01.csv\n",
      "Financials bronze processing completed for 24 snapshots\n"
     ]
    }
   ],
   "source": [
    "# Process Bronze Layer - Financial Features\n",
    "print(\"=== Processing Bronze Layer - Financials ===\")\n",
    "for i, date_str in enumerate(dates_str_lst):\n",
    "    if i % 6 == 0:  # Print progress every 6 months\n",
    "        print(f\"Processing financials bronze for {date_str}...\")\n",
    "    \n",
    "    utils.feature_processing_bronze_table.process_financials_bronze_table(\n",
    "        date_str, bronze_financials_directory, spark)\n",
    "\n",
    "print(f\"Financials bronze processing completed for {len(dates_str_lst)} snapshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bronze Layer Sample Inspection ===\n",
      "Inspecting data for 2024-12-01\n",
      "Clickstream 2024-12-01 row count: 8974\n",
      "Clickstream bronze saved to: datamart/bronze/clickstream/bronze_clickstream_2024_12_01.csv\n",
      "\n",
      "Clickstream bronze shape: 8974 rows, 25 columns\n",
      "+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----------+-------------+--------------------+-------------------+---------------+\n",
      "|fe_1|fe_2|fe_3|fe_4|fe_5|fe_6|fe_7|fe_8|fe_9|fe_10|fe_11|fe_12|fe_13|fe_14|fe_15|fe_16|fe_17|fe_18|fe_19|fe_20|Customer_ID|snapshot_date| ingestion_timestamp|        data_source|processing_date|\n",
      "+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----------+-------------+--------------------+-------------------+---------------+\n",
      "| 145| 189| 109| 134| 196| -37| 101|  82| 111|   24|  -26|  -17|   65|  249|  200|  185|  -83|  -18|  -76|   30| CUS_0x1037|   2024-12-01|2025-05-22 08:02:...|feature_clickstream|     2024-12-01|\n",
      "|  40| 184| 187|  75| 192| 146|  38| 109| 353|  141|   -9|  -22|  -14|  193|  125|  117|  215|   91|   33|  255| CUS_0x1069|   2024-12-01|2025-05-22 08:02:...|feature_clickstream|     2024-12-01|\n",
      "|  98| 121| 180| 200|  95|  48|  59| 194|  76|   84|  298|  -57|  167|  101|   92|  185|   98|   68|  -60|  116| CUS_0x114a|   2024-12-01|2025-05-22 08:02:...|feature_clickstream|     2024-12-01|\n",
      "|  85|  96|  19|  47|  30|  39| -32| 210| -81|  206|   37|  105|  143|   94|  139|  237|   78|  187|   77|   33| CUS_0x1184|   2024-12-01|2025-05-22 08:02:...|feature_clickstream|     2024-12-01|\n",
      "|  98|  45| 155|  56| 112|  47|  52| 138| 153|  225|   31|   40|  -43|  142|  121|   10|  189|  110|  264|  241| CUS_0x1297|   2024-12-01|2025-05-22 08:02:...|feature_clickstream|     2024-12-01|\n",
      "+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----------+-------------+--------------------+-------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect bronze layer outputs\n",
    "sample_date = dates_str_lst[-1]  # Use the latest date for inspection\n",
    "\n",
    "print(\"=== Bronze Layer Sample Inspection ===\")\n",
    "print(f\"Inspecting data for {sample_date}\")\n",
    "\n",
    "# Sample clickstream bronze\n",
    "clickstream_sample = utils.feature_processing_bronze_table.process_clickstream_bronze_table(\n",
    "    sample_date, bronze_clickstream_directory, spark)\n",
    "print(f\"\\nClickstream bronze shape: {clickstream_sample.count()} rows, {len(clickstream_sample.columns)} columns\")\n",
    "clickstream_sample.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver Layer - Data Cleaning and Standardization\n",
    "\n",
    "The Silver layer applies data quality improvements and standardization while maintaining time-awareness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: ../datamart/silver/clickstream/\n",
      "Created directory: ../datamart/silver/attributes/\n",
      "Created directory: ../datamart/silver/financials/\n"
     ]
    }
   ],
   "source": [
    "# Create silver layer directories\n",
    "silver_clickstream_directory = \"../datamart/silver/clickstream/\"\n",
    "silver_attributes_directory = \"../datamart/silver/attributes/\"\n",
    "silver_financials_directory = \"../datamart/silver/financials/\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [silver_clickstream_directory, silver_attributes_directory, silver_financials_directory]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Silver Layer - Clickstream ===\n",
      "Processing clickstream silver for 2023-01-01...\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_01_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_01_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_02_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_02_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_03_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_03_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_04_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_04_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_05_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_05_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_06_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_06_01.parquet\n",
      "Processing clickstream silver for 2023-07-01...\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_07_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_07_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_08_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_08_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_09_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_09_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_10_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_10_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_11_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_11_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2023_12_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2023_12_01.parquet\n",
      "Processing clickstream silver for 2024-01-01...\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_01_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_01_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_02_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_02_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_03_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_03_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_04_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_04_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_05_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_05_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_06_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_06_01.parquet\n",
      "Processing clickstream silver for 2024-07-01...\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_07_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_07_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_08_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_08_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_09_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_09_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_10_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_10_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_11_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_11_01.parquet\n",
      "Clickstream silver loaded from: datamart/bronze/clickstream/bronze_clickstream_2024_12_01.csv, row count: 8974\n",
      "Clickstream silver saved to: ../datamart/silver/clickstream/silver_clickstream_2024_12_01.parquet\n",
      "Clickstream silver processing completed for 24 snapshots\n"
     ]
    }
   ],
   "source": [
    "# Process Silver Layer - Clickstream Features\n",
    "print(\"=== Processing Silver Layer - Clickstream ===\")\n",
    "for i, date_str in enumerate(dates_str_lst):\n",
    "    if i % 6 == 0:  # Print progress every 6 months\n",
    "        print(f\"Processing clickstream silver for {date_str}...\")\n",
    "    \n",
    "    utils.feature_processing_silver_table.process_clickstream_silver_table(\n",
    "        date_str, bronze_clickstream_directory, silver_clickstream_directory, spark)\n",
    "\n",
    "print(f\"Clickstream silver processing completed for {len(dates_str_lst)} snapshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Silver Layer - Attributes ===\n",
      "Processing attributes silver for 2023-01-01...\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_01_01.csv, row count: 530\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_01_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_02_01.csv, row count: 501\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_02_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_03_01.csv, row count: 506\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_03_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_04_01.csv, row count: 510\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_04_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_05_01.csv, row count: 521\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_05_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_06_01.csv, row count: 517\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_06_01.parquet\n",
      "Processing attributes silver for 2023-07-01...\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_07_01.csv, row count: 471\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_07_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_08_01.csv, row count: 481\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_08_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_09_01.csv, row count: 454\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_09_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_10_01.csv, row count: 487\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_10_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_11_01.csv, row count: 491\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_11_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2023_12_01.csv, row count: 489\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2023_12_01.parquet\n",
      "Processing attributes silver for 2024-01-01...\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_01_01.csv, row count: 485\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_01_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_02_01.csv, row count: 518\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_02_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_03_01.csv, row count: 511\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_03_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_04_01.csv, row count: 513\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_04_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_05_01.csv, row count: 491\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_05_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_06_01.csv, row count: 498\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_06_01.parquet\n",
      "Processing attributes silver for 2024-07-01...\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_07_01.csv, row count: 505\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_07_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_08_01.csv, row count: 543\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_08_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_09_01.csv, row count: 493\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_09_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_10_01.csv, row count: 456\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_10_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_11_01.csv, row count: 488\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_11_01.parquet\n",
      "Attributes silver loaded from: datamart/bronze/attributes/bronze_attributes_2024_12_01.csv, row count: 515\n",
      "Attributes silver saved to: ../datamart/silver/attributes/silver_attributes_2024_12_01.parquet\n",
      "Attributes silver processing completed for 24 snapshots\n"
     ]
    }
   ],
   "source": [
    "# Process Silver Layer - Customer Attributes\n",
    "print(\"=== Processing Silver Layer - Attributes ===\")\n",
    "for i, date_str in enumerate(dates_str_lst):\n",
    "    if i % 6 == 0:  # Print progress every 6 months\n",
    "        print(f\"Processing attributes silver for {date_str}...\")\n",
    "    \n",
    "    utils.feature_processing_silver_table.process_attributes_silver_table(\n",
    "        date_str, bronze_attributes_directory, silver_attributes_directory, spark)\n",
    "\n",
    "print(f\"Attributes silver processing completed for {len(dates_str_lst)} snapshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Silver Layer - Financials ===\n",
      "Processing financials silver for 2023-01-01...\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_01_01.csv, row count: 530\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_01_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_02_01.csv, row count: 501\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_02_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_03_01.csv, row count: 506\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_03_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_04_01.csv, row count: 510\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_04_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_05_01.csv, row count: 521\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_05_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_06_01.csv, row count: 517\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_06_01.parquet\n",
      "Processing financials silver for 2023-07-01...\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_07_01.csv, row count: 471\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_07_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_08_01.csv, row count: 481\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_08_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_09_01.csv, row count: 454\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_09_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_10_01.csv, row count: 487\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_10_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_11_01.csv, row count: 491\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_11_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2023_12_01.csv, row count: 489\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2023_12_01.parquet\n",
      "Processing financials silver for 2024-01-01...\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_01_01.csv, row count: 485\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_01_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_02_01.csv, row count: 518\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_02_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_03_01.csv, row count: 511\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_03_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_04_01.csv, row count: 513\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_04_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_05_01.csv, row count: 491\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_05_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_06_01.csv, row count: 498\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_06_01.parquet\n",
      "Processing financials silver for 2024-07-01...\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_07_01.csv, row count: 505\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_07_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_08_01.csv, row count: 543\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_08_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_09_01.csv, row count: 493\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_09_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_10_01.csv, row count: 456\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_10_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_11_01.csv, row count: 488\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_11_01.parquet\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_12_01.csv, row count: 515\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_12_01.parquet\n",
      "Financials silver processing completed for 24 snapshots\n"
     ]
    }
   ],
   "source": [
    "# Process Silver Layer - Financial Features\n",
    "print(\"=== Processing Silver Layer - Financials ===\")\n",
    "for i, date_str in enumerate(dates_str_lst):\n",
    "    if i % 6 == 0:  # Print progress every 6 months\n",
    "        print(f\"Processing financials silver for {date_str}...\")\n",
    "    \n",
    "    utils.feature_processing_silver_table.process_financials_silver_table(\n",
    "        date_str, bronze_financials_directory, silver_financials_directory, spark)\n",
    "\n",
    "print(f\"Financials silver processing completed for {len(dates_str_lst)} snapshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Silver Layer Sample Inspection ===\n",
      "Inspecting cleaned data for 2024-12-01\n",
      "Financials silver loaded from: datamart/bronze/financials/bronze_financials_2024_12_01.csv, row count: 515\n",
      "Financials silver saved to: ../datamart/silver/financials/silver_financials_2024_12_01.parquet\n",
      "\n",
      "Financial silver shape: 515 rows, 34 columns\n",
      "\n",
      "Sample of cleaned financial features:\n",
      "+-----------+-------------------+----------------+--------------------+--------------------+\n",
      "|Customer_ID|Annual_Income_clean|Credit_Mix_clean|debt_to_income_ratio| emi_to_income_ratio|\n",
      "+-----------+-------------------+----------------+--------------------+--------------------+\n",
      "| CUS_0x103e|            98690.8|            Good|0.007163383459838501|0.006657328996024...|\n",
      "| CUS_0x1195|           30429.91|        Standard|0.011911964548205489|0.010650028382346001|\n",
      "| CUS_0x1197|           92300.01|         Unknown|0.008181689263171277|   6.619817318977127|\n",
      "| CUS_0x11e2|           44986.55|            Good|0.016743004495614444|0.006305663321698229|\n",
      "| CUS_0x11ec|           14867.69|        Standard|  0.1576613442201607| 0.05513024423607961|\n",
      "+-----------+-------------------+----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect silver layer outputs\n",
    "print(\"=== Silver Layer Sample Inspection ===\")\n",
    "print(f\"Inspecting cleaned data for {sample_date}\")\n",
    "\n",
    "# Sample financial silver with cleaned features\n",
    "financial_sample = utils.feature_processing_silver_table.process_financials_silver_table(\n",
    "    sample_date, bronze_financials_directory, silver_financials_directory, spark)\n",
    "print(f\"\\nFinancial silver shape: {financial_sample.count()} rows, {len(financial_sample.columns)} columns\")\n",
    "print(\"\\nSample of cleaned financial features:\")\n",
    "financial_sample.select(\"Customer_ID\", \"Annual_Income_clean\", \"Credit_Mix_clean\", \n",
    "                       \"debt_to_income_ratio\", \"emi_to_income_ratio\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Layer - ML-Ready Feature Store\n",
    "\n",
    "The Gold layer creates machine learning-ready features by combining all data sources with time-aware aggregations and interaction features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: ../datamart/gold/feature_store/\n"
     ]
    }
   ],
   "source": [
    "# Create gold layer directory\n",
    "gold_feature_store_directory = \"../datamart/gold/feature_store/\"\n",
    "\n",
    "if not os.path.exists(gold_feature_store_directory):\n",
    "    os.makedirs(gold_feature_store_directory)\n",
    "    print(f\"Created directory: {gold_feature_store_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Gold Layer - Feature Store ===\n",
      "Creating ML-ready features with 6-month lookback period\n",
      "Skipping 2023-01-01 - insufficient lookback history\n",
      "Skipping 2023-02-01 - insufficient lookback history\n",
      "Skipping 2023-03-01 - insufficient lookback history\n",
      "Skipping 2023-04-01 - insufficient lookback history\n",
      "Skipping 2023-05-01 - insufficient lookback history\n",
      "Processing feature store for 2023-07-01...\n",
      "Processing features for 2023-07-01 with lookback to 2023-01-01\n",
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 3556 customers\n",
      "Financial features processed for 3556 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2023_07_01.parquet\n",
      "Processing features for 2023-08-01 with lookback to 2023-02-01\n",
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 4037 customers\n",
      "Financial features processed for 4037 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2023_08_01.parquet\n",
      "Processing features for 2023-09-01 with lookback to 2023-03-01\n",
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 4491 customers\n",
      "Financial features processed for 4491 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2023_09_01.parquet\n",
      "Processing features for 2023-10-01 with lookback to 2023-04-01\n",
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 4978 customers\n",
      "Financial features processed for 4978 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2023_10_01.parquet\n",
      "Processing features for 2023-11-01 with lookback to 2023-05-01\n",
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 5469 customers\n",
      "Financial features processed for 5469 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2023_11_01.parquet\n",
      "Processing features for 2023-12-01 with lookback to 2023-06-01\n",
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 5958 customers\n",
      "Financial features processed for 5958 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2023_12_01.parquet\n",
      "Processing feature store for 2024-01-01...\n",
      "Processing features for 2024-01-01 with lookback to 2023-07-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 6443 customers\n",
      "Financial features processed for 6443 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_01_01.parquet\n",
      "Processing features for 2024-02-01 with lookback to 2023-08-01\n",
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 6961 customers\n",
      "Financial features processed for 6961 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_02_01.parquet\n",
      "Processing features for 2024-03-01 with lookback to 2023-09-01\n",
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 7472 customers\n",
      "Financial features processed for 7472 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_03_01.parquet\n",
      "Processing features for 2024-04-01 with lookback to 2023-10-01\n",
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 7985 customers\n",
      "Financial features processed for 7985 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_04_01.parquet\n",
      "Processing features for 2024-05-01 with lookback to 2023-11-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 8476 customers\n",
      "Financial features processed for 8476 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_05_01.parquet\n",
      "Processing features for 2024-06-01 with lookback to 2023-12-01\n",
      "Found 8974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 8974 customers\n",
      "Financial features processed for 8974 customers\n",
      "Combined features for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_06_01.parquet\n",
      "Processing feature store for 2024-07-01...\n",
      "Processing features for 2024-07-01 with lookback to 2024-01-01\n",
      "Found 9479 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 9479 customers\n",
      "Financial features processed for 9479 customers\n",
      "Combined features for 9479 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_07_01.parquet\n",
      "Processing features for 2024-08-01 with lookback to 2024-02-01\n",
      "Found 10022 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 10022 customers\n",
      "Financial features processed for 10022 customers\n",
      "Combined features for 10022 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_08_01.parquet\n",
      "Processing features for 2024-09-01 with lookback to 2024-03-01\n",
      "Found 10515 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 10515 customers\n",
      "Financial features processed for 10515 customers\n",
      "Combined features for 10515 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_09_01.parquet\n",
      "Processing features for 2024-10-01 with lookback to 2024-04-01\n",
      "Found 10971 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 10971 customers\n",
      "Financial features processed for 10971 customers\n",
      "Combined features for 10971 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_10_01.parquet\n",
      "Processing features for 2024-11-01 with lookback to 2024-05-01\n",
      "Found 11459 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 11459 customers\n",
      "Financial features processed for 11459 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features for 11459 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_11_01.parquet\n",
      "Processing features for 2024-12-01 with lookback to 2024-06-01\n",
      "Found 11974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n",
      "Attributes features processed for 11974 customers\n",
      "Financial features processed for 11974 customers\n",
      "Combined features for 11974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5204:>                                                       (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_12_01.parquet\n",
      "Gold feature store processing completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Process Gold Layer - Integrated Feature Store\n",
    "print(\"=== Processing Gold Layer - Feature Store ===\")\n",
    "print(f\"Creating ML-ready features with {lookback_months}-month lookback period\")\n",
    "\n",
    "for i, date_str in enumerate(dates_str_lst):\n",
    "    # Only process dates that have sufficient lookback history\n",
    "    current_date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # Check if we have enough history for this date\n",
    "    months_since_start = (current_date.year - start_date.year) * 12 + current_date.month - start_date.month\n",
    "    \n",
    "    if months_since_start >= lookback_months:\n",
    "        if i % 6 == 0:  # Print progress every 6 months\n",
    "            print(f\"Processing feature store for {date_str}...\")\n",
    "        \n",
    "        utils.feature_processing_gold_table.process_features_gold_table(\n",
    "            date_str, \n",
    "            silver_clickstream_directory, \n",
    "            silver_attributes_directory, \n",
    "            silver_financials_directory, \n",
    "            gold_feature_store_directory, \n",
    "            spark, \n",
    "            lookback_months=lookback_months\n",
    "        )\n",
    "    else:\n",
    "        if i < 5:  # Only print for first few skipped dates\n",
    "            print(f\"Skipping {date_str} - insufficient lookback history\")\n",
    "\n",
    "print(f\"Gold feature store processing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gold Layer Feature Store Inspection ===\n",
      "Inspecting feature store for 2024-12-01\n",
      "Processing features for 2024-12-01 with lookback to 2024-06-01\n",
      "Found 11974 unique customers across all data sources\n",
      "Clickstream features processed for 8974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes features processed for 11974 customers\n",
      "Financial features processed for 11974 customers\n",
      "Combined features for 11974 customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold feature store saved to: ../datamart/gold/feature_store/gold_feature_store_2024_12_01.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature store shape: 11974 rows, 137 columns\n",
      "\n",
      "Feature store schema:\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- annual_income: float (nullable = true)\n",
      " |-- monthly_salary: float (nullable = true)\n",
      " |-- credit_mix: string (nullable = true)\n",
      " |-- payment_of_min_amount: string (nullable = true)\n",
      " |-- credit_history_months: integer (nullable = true)\n",
      " |-- credit_utilization_ratio: float (nullable = true)\n",
      " |-- delay_from_due_date: integer (nullable = true)\n",
      " |-- num_loans: float (nullable = true)\n",
      " |-- num_delayed_payments: float (nullable = true)\n",
      " |-- outstanding_debt: float (nullable = true)\n",
      " |-- total_emi_monthly: float (nullable = true)\n",
      " |-- amount_invested_monthly: float (nullable = true)\n",
      " |-- monthly_balance: float (nullable = true)\n",
      " |-- debt_to_income_ratio: double (nullable = true)\n",
      " |-- emi_to_income_ratio: double (nullable = true)\n",
      " |-- high_credit_utilization: integer (nullable = true)\n",
      " |-- high_debt_burden: integer (nullable = true)\n",
      " |-- payment_issues: integer (nullable = true)\n",
      " |-- financial_health_score: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- age_is_valid: boolean (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- ssn_is_valid: boolean (nullable = true)\n",
      " |-- attributes_quality_score: double (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- occupation_category: string (nullable = true)\n",
      " |-- fe_1_mean: double (nullable = true)\n",
      " |-- fe_1_std: double (nullable = true)\n",
      " |-- fe_1_min: float (nullable = true)\n",
      " |-- fe_1_max: float (nullable = true)\n",
      " |-- fe_2_mean: double (nullable = true)\n",
      " |-- fe_2_std: double (nullable = true)\n",
      " |-- fe_2_min: float (nullable = true)\n",
      " |-- fe_2_max: float (nullable = true)\n",
      " |-- fe_3_mean: double (nullable = true)\n",
      " |-- fe_3_std: double (nullable = true)\n",
      " |-- fe_3_min: float (nullable = true)\n",
      " |-- fe_3_max: float (nullable = true)\n",
      " |-- fe_4_mean: double (nullable = true)\n",
      " |-- fe_4_std: double (nullable = true)\n",
      " |-- fe_4_min: float (nullable = true)\n",
      " |-- fe_4_max: float (nullable = true)\n",
      " |-- fe_5_mean: double (nullable = true)\n",
      " |-- fe_5_std: double (nullable = true)\n",
      " |-- fe_5_min: float (nullable = true)\n",
      " |-- fe_5_max: float (nullable = true)\n",
      " |-- fe_6_mean: double (nullable = true)\n",
      " |-- fe_6_std: double (nullable = true)\n",
      " |-- fe_6_min: float (nullable = true)\n",
      " |-- fe_6_max: float (nullable = true)\n",
      " |-- fe_7_mean: double (nullable = true)\n",
      " |-- fe_7_std: double (nullable = true)\n",
      " |-- fe_7_min: float (nullable = true)\n",
      " |-- fe_7_max: float (nullable = true)\n",
      " |-- fe_8_mean: double (nullable = true)\n",
      " |-- fe_8_std: double (nullable = true)\n",
      " |-- fe_8_min: float (nullable = true)\n",
      " |-- fe_8_max: float (nullable = true)\n",
      " |-- fe_9_mean: double (nullable = true)\n",
      " |-- fe_9_std: double (nullable = true)\n",
      " |-- fe_9_min: float (nullable = true)\n",
      " |-- fe_9_max: float (nullable = true)\n",
      " |-- fe_10_mean: double (nullable = true)\n",
      " |-- fe_10_std: double (nullable = true)\n",
      " |-- fe_10_min: float (nullable = true)\n",
      " |-- fe_10_max: float (nullable = true)\n",
      " |-- fe_11_mean: double (nullable = true)\n",
      " |-- fe_11_std: double (nullable = true)\n",
      " |-- fe_11_min: float (nullable = true)\n",
      " |-- fe_11_max: float (nullable = true)\n",
      " |-- fe_12_mean: double (nullable = true)\n",
      " |-- fe_12_std: double (nullable = true)\n",
      " |-- fe_12_min: float (nullable = true)\n",
      " |-- fe_12_max: float (nullable = true)\n",
      " |-- fe_13_mean: double (nullable = true)\n",
      " |-- fe_13_std: double (nullable = true)\n",
      " |-- fe_13_min: float (nullable = true)\n",
      " |-- fe_13_max: float (nullable = true)\n",
      " |-- fe_14_mean: double (nullable = true)\n",
      " |-- fe_14_std: double (nullable = true)\n",
      " |-- fe_14_min: float (nullable = true)\n",
      " |-- fe_14_max: float (nullable = true)\n",
      " |-- fe_15_mean: double (nullable = true)\n",
      " |-- fe_15_std: double (nullable = true)\n",
      " |-- fe_15_min: float (nullable = true)\n",
      " |-- fe_15_max: float (nullable = true)\n",
      " |-- fe_16_mean: double (nullable = true)\n",
      " |-- fe_16_std: double (nullable = true)\n",
      " |-- fe_16_min: float (nullable = true)\n",
      " |-- fe_16_max: float (nullable = true)\n",
      " |-- fe_17_mean: double (nullable = true)\n",
      " |-- fe_17_std: double (nullable = true)\n",
      " |-- fe_17_min: float (nullable = true)\n",
      " |-- fe_17_max: float (nullable = true)\n",
      " |-- fe_18_mean: double (nullable = true)\n",
      " |-- fe_18_std: double (nullable = true)\n",
      " |-- fe_18_min: float (nullable = true)\n",
      " |-- fe_18_max: float (nullable = true)\n",
      " |-- fe_19_mean: double (nullable = true)\n",
      " |-- fe_19_std: double (nullable = true)\n",
      " |-- fe_19_min: float (nullable = true)\n",
      " |-- fe_19_max: float (nullable = true)\n",
      " |-- fe_20_mean: double (nullable = true)\n",
      " |-- fe_20_std: double (nullable = true)\n",
      " |-- fe_20_min: float (nullable = true)\n",
      " |-- fe_20_max: float (nullable = true)\n",
      " |-- clickstream_record_count: long (nullable = true)\n",
      " |-- clickstream_time_span_days: integer (nullable = true)\n",
      " |-- fe_1_cv: double (nullable = true)\n",
      " |-- fe_2_cv: double (nullable = true)\n",
      " |-- fe_3_cv: double (nullable = true)\n",
      " |-- fe_4_cv: double (nullable = true)\n",
      " |-- fe_5_cv: double (nullable = true)\n",
      " |-- fe_6_cv: double (nullable = true)\n",
      " |-- fe_7_cv: double (nullable = true)\n",
      " |-- fe_8_cv: double (nullable = true)\n",
      " |-- fe_9_cv: double (nullable = true)\n",
      " |-- fe_10_cv: double (nullable = true)\n",
      " |-- fe_11_cv: double (nullable = true)\n",
      " |-- fe_12_cv: double (nullable = true)\n",
      " |-- fe_13_cv: double (nullable = true)\n",
      " |-- fe_14_cv: double (nullable = true)\n",
      " |-- fe_15_cv: double (nullable = true)\n",
      " |-- fe_16_cv: double (nullable = true)\n",
      " |-- fe_17_cv: double (nullable = true)\n",
      " |-- fe_18_cv: double (nullable = true)\n",
      " |-- fe_19_cv: double (nullable = true)\n",
      " |-- fe_20_cv: double (nullable = true)\n",
      " |-- feature_snapshot_date: string (nullable = false)\n",
      " |-- age_income_interaction: double (nullable = true)\n",
      " |-- relative_credit_history: double (nullable = true)\n",
      " |-- age_adjusted_debt_ratio: double (nullable = true)\n",
      " |-- has_clickstream_data: integer (nullable = false)\n",
      " |-- has_attributes_data: integer (nullable = false)\n",
      " |-- has_financial_data: integer (nullable = false)\n",
      " |-- data_completeness_score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect gold layer feature store\n",
    "print(\"=== Gold Layer Feature Store Inspection ===\")\n",
    "\n",
    "# Use a date with sufficient history\n",
    "inspection_date = dates_str_lst[-1]  # Latest date\n",
    "print(f\"Inspecting feature store for {inspection_date}\")\n",
    "\n",
    "# Load and inspect the gold feature store\n",
    "feature_sample = utils.feature_processing_gold_table.process_features_gold_table(\n",
    "    inspection_date, \n",
    "    silver_clickstream_directory, \n",
    "    silver_attributes_directory, \n",
    "    silver_financials_directory, \n",
    "    gold_feature_store_directory, \n",
    "    spark, \n",
    "    lookback_months=lookback_months\n",
    ")\n",
    "\n",
    "print(f\"\\nFeature store shape: {feature_sample.count()} rows, {len(feature_sample.columns)} columns\")\n",
    "print(f\"\\nFeature store schema:\")\n",
    "feature_sample.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample of Key Features ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------------------+------------------------+----------------------+--------------------+-------------------+------------------+-----------------------+---------------------+\n",
      "|Customer_ID|annual_income|age|occupation_category|credit_utilization_ratio|financial_health_score|has_clickstream_data|has_attributes_data|has_financial_data|data_completeness_score|feature_snapshot_date|\n",
      "+-----------+-------------+---+-------------------+------------------------+----------------------+--------------------+-------------------+------------------+-----------------------+---------------------+\n",
      "|CUS_0x3383 |148990.16    |31 |Unknown            |33.24051                |0.4                   |1                   |1                  |1                 |1.0                    |2024-12-01           |\n",
      "|CUS_0xb8de |17538.28     |30 |Professional       |36.147934               |0.4                   |1                   |1                  |1                 |1.0                    |2024-12-01           |\n",
      "|CUS_0xb4be |20354.85     |19 |Professional       |38.027798               |0.4                   |1                   |1                  |1                 |1.0                    |2024-12-01           |\n",
      "|CUS_0x5f86 |17234.695    |25 |Other              |30.989706               |0.4                   |1                   |1                  |1                 |1.0                    |2024-12-01           |\n",
      "|CUS_0x8135 |344983.0     |32 |Education_Research |28.302124               |0.8                   |1                   |1                  |1                 |1.0                    |2024-12-01           |\n",
      "|CUS_0x5845 |57295.88     |36 |Education_Research |37.74249                |0.4                   |0                   |1                  |1                 |0.6666666666666666     |2024-12-01           |\n",
      "|CUS_0xf43  |82998.24     |38 |Technology_Media   |26.694296               |0.6                   |0                   |1                  |1                 |0.6666666666666666     |2024-12-01           |\n",
      "|CUS_0x73c0 |77004.92     |43 |Other              |38.12569                |0.4                   |1                   |1                  |1                 |1.0                    |2024-12-01           |\n",
      "|CUS_0x5b70 |83378.2      |55 |Other              |29.963999               |0.4                   |1                   |1                  |1                 |1.0                    |2024-12-01           |\n",
      "|CUS_0x11fc |38735.57     |30 |Professional       |36.785755               |0.4                   |1                   |1                  |1                 |1.0                    |2024-12-01           |\n",
      "+-----------+-------------+---+-------------------+------------------------+----------------------+--------------------+-------------------+------------------+-----------------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display sample of key features\n",
    "print(\"=== Sample of Key Features ===\")\n",
    "\n",
    "# Select key features for display\n",
    "key_features = [\n",
    "    \"Customer_ID\", \"annual_income\", \"age\", \"occupation_category\", \n",
    "    \"credit_utilization_ratio\", \"financial_health_score\", \n",
    "    \"has_clickstream_data\", \"has_attributes_data\", \"has_financial_data\",\n",
    "    \"data_completeness_score\", \"feature_snapshot_date\"\n",
    "]\n",
    "\n",
    "# Filter to show only columns that exist\n",
    "existing_key_features = [col for col in key_features if col in feature_sample.columns]\n",
    "\n",
    "feature_sample.select(*existing_key_features).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feature Store Statistics ===\n",
      "Data Availability Summary:\n",
      "Clickstream Data Coverage: 74.95%\n",
      "Attributes Data Coverage: 100.00%\n",
      "Financial Data Coverage: 100.00%\n",
      "Average Completeness Score: 0.916\n"
     ]
    }
   ],
   "source": [
    "# Feature store statistics and summary\n",
    "print(\"=== Feature Store Statistics ===\")\n",
    "\n",
    "# Check data availability distribution\n",
    "print(\"Data Availability Summary:\")\n",
    "availability_stats = feature_sample.select(\n",
    "    F.avg(\"has_clickstream_data\").alias(\"clickstream_coverage\"),\n",
    "    F.avg(\"has_attributes_data\").alias(\"attributes_coverage\"),\n",
    "    F.avg(\"has_financial_data\").alias(\"financial_coverage\"),\n",
    "    F.avg(\"data_completeness_score\").alias(\"avg_completeness_score\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Clickstream Data Coverage: {availability_stats['clickstream_coverage']:.2%}\")\n",
    "print(f\"Attributes Data Coverage: {availability_stats['attributes_coverage']:.2%}\")\n",
    "print(f\"Financial Data Coverage: {availability_stats['financial_coverage']:.2%}\")\n",
    "print(f\"Average Completeness Score: {availability_stats['avg_completeness_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Complete Feature Store Analysis ===\n",
      "\n",
      "Complete feature store shape: 172108 rows, 137 columns\n",
      "\n",
      "Feature store time distribution:\n",
      "+---------------------+-----+\n",
      "|feature_snapshot_date|count|\n",
      "+---------------------+-----+\n",
      "|           2023-07-01| 8974|\n",
      "|           2023-08-01| 8974|\n",
      "|           2023-09-01| 8974|\n",
      "|           2023-10-01| 8974|\n",
      "|           2023-11-01| 8974|\n",
      "|           2023-12-01| 8974|\n",
      "|           2024-01-01| 8974|\n",
      "|           2024-02-01| 8974|\n",
      "|           2024-03-01| 8974|\n",
      "|           2024-04-01| 8974|\n",
      "|           2024-05-01| 8974|\n",
      "|           2024-06-01| 8974|\n",
      "|           2024-07-01| 9479|\n",
      "|           2024-08-01|10022|\n",
      "|           2024-09-01|10515|\n",
      "|           2024-10-01|10971|\n",
      "|           2024-11-01|11459|\n",
      "|           2024-12-01|11974|\n",
      "+---------------------+-----+\n",
      "\n",
      "\n",
      "Feature engineering pipeline completed successfully!\n",
      "Total records processed: 172108\n",
      "Time periods covered: 18\n"
     ]
    }
   ],
   "source": [
    "# Load and inspect the complete feature store across all time periods\n",
    "print(\"=== Complete Feature Store Analysis ===\")\n",
    "\n",
    "# Load all feature store files\n",
    "folder_path = gold_feature_store_directory\n",
    "files_list = [folder_path + os.path.basename(f) for f in glob.glob(os.path.join(folder_path, '*'))]\n",
    "\n",
    "if files_list:\n",
    "    complete_feature_store = spark.read.option(\"header\", \"true\").parquet(*files_list)\n",
    "    print(f\"\\nComplete feature store shape: {complete_feature_store.count()} rows, {len(complete_feature_store.columns)} columns\")\n",
    "    \n",
    "    # Show time distribution\n",
    "    print(\"\\nFeature store time distribution:\")\n",
    "    time_dist = complete_feature_store.groupBy(\"feature_snapshot_date\").count().orderBy(\"feature_snapshot_date\")\n",
    "    time_dist.show()\n",
    "    \n",
    "    print(\"\\nFeature engineering pipeline completed successfully!\")\n",
    "    print(f\"Total records processed: {complete_feature_store.count()}\")\n",
    "    print(f\"Time periods covered: {time_dist.count()}\")\n",
    "else:\n",
    "    print(\"No feature store files found. Please check the processing steps above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Summary\n",
    "\n",
    "This pipeline has successfully created a comprehensive feature store with customer-centric data integration and time-aware processing:\n",
    "\n",
    "### Data Processing Results:\n",
    "- **Total Records Processed**: 172,108 feature records across 18 time periods\n",
    "- **Customer Coverage**: 11,974 unique customers with complete feature profiles\n",
    "- **Feature Dimensions**: 137 engineered features per customer per time period\n",
    "- **Temporal Coverage**: July 2023 to December 2024 with 6-month lookback periods\n",
    "\n",
    "### Data Processing Layers:\n",
    "- **Bronze Layer**: Raw data preservation with metadata tracking across 3 data sources (clickstream, attributes, financials)\n",
    "- **Silver Layer**: Data quality improvements including underscore removal, format standardization, and categorical cleaning\n",
    "- **Gold Layer**: Customer-centric ML-ready feature aggregations using \"most recent available\" data strategy\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "1. **Behavioral Features (80 features)**:\n",
    "   - Time-aware clickstream aggregations (fe_1 through fe_20: mean, std, min, max)\n",
    "   - Behavioral stability metrics (coefficient of variation for each feature)\n",
    "   - Activity metrics (record count, time span, engagement patterns)\n",
    "\n",
    "2. **Demographic Features (7 features)**:\n",
    "   - Cleaned age groups (18-29, 30-39, 40-49, 50-59, 60+)\n",
    "   - Occupation categories (Professional, Education_Research, Technology_Media, Technical_Services, Other)\n",
    "   - Data quality indicators (age validity, SSN validity, overall quality score)\n",
    "\n",
    "3. **Financial Features (20 features)**:\n",
    "   - Core financial metrics (income, credit utilization, payment history)\n",
    "   - Derived risk indicators (debt-to-income ratio, EMI-to-income ratio)\n",
    "   - Financial health score (composite 0-1 scale based on 5 risk factors)\n",
    "   - Binary risk flags (high credit utilization, high debt burden, payment issues)\n",
    "\n",
    "4. **Interaction Features (3 features)**:\n",
    "   - Age-income interaction (normalized)\n",
    "   - Relative credit history (credit months/age ratio)\n",
    "   - Age-adjusted debt ratio (debt ratio weighted by age)\n",
    "\n",
    "5. **Data Quality Features (4 features)**:\n",
    "   - Source availability flags (has_clickstream_data, has_attributes_data, has_financial_data)\n",
    "   - Overall completeness score (0-1 scale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
